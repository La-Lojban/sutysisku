/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
/******/ (() => { // webpackBootstrap
/******/ 	"use strict";
/******/ 	var __webpack_modules__ = ({

/***/ "../../node_modules/perf-deets/index.js":
/*!**********************************************!*\
  !*** ../../node_modules/perf-deets/index.js ***!
  \**********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"start\": () => (/* binding */ start),\n/* harmony export */   \"stop\": () => (/* binding */ stop),\n/* harmony export */   \"record\": () => (/* binding */ record),\n/* harmony export */   \"endRecording\": () => (/* binding */ endRecording),\n/* harmony export */   \"count\": () => (/* binding */ count)\n/* harmony export */ });\nlet buffer = 40000;\nlet baseTime;\nlet timings = {};\nlet counts = {};\n\nlet apiVersion = 1;\n\nconsole.warn(\n  'perf-deets loaded. If this is the production bundle, you should remove it'\n);\n\nfunction last(arr) {\n  return arr.length === 0 ? null : arr[arr.length - 1];\n}\n\nasync function writeData(type, name, data) {\n  globalThis.postMessage({\n    type: '__perf-deets:log-perf',\n    dataType: type,\n    name,\n    data,\n    apiVersion\n  });\n}\n\nfunction start() {\n  globalThis.postMessage({ type: '__perf-deets:clear-perf' });\n\n  timings = {};\n  counts = {};\n  baseTime = performance.now();\n}\n\nasync function stop() {\n  Object.keys(timings).map(name => {\n    let timing = timings[name];\n    writeData(\n      'timing',\n      name,\n      timing.data.map(x => ({ x: x.start + x.took, y: x.took }))\n    );\n  });\n\n  Object.keys(counts).map(name => {\n    let count = counts[name];\n    writeData('count', name, count.map((c, i) => ({ x: c.time, y: i })));\n  });\n}\n\nfunction record(name) {\n  if (timings[name] == null) {\n    timings[name] = { start: null, data: [] };\n  }\n  let timer = timings[name];\n\n  if (timer.start != null) {\n    throw new Error(`timer already started ${name}`);\n  }\n  timer.start = performance.now();\n}\n\nfunction endRecording(name) {\n  let now = performance.now();\n  let timer = timings[name];\n\n  if (timer && timer.start != null) {\n    let took = now - timer.start;\n    let start = timer.start - baseTime;\n    timer.start = null;\n\n    if (timer.data.length < buffer) {\n      timer.data.push({ start, took });\n    }\n  }\n}\n\nfunction count(name) {\n  if (counts[name] == null) {\n    counts[name] = [];\n  }\n  counts[name].push({ time: performance.now() });\n}\n\n// TODO: To support other environments/setups, we should abstract how\n// to communicate to this package and allow custom protocols. While\n// the message handler below is just a convenience, to log data we\n// currently use `postMessage` which makes assumptions about the\n// environment\nif (globalThis.addEventListener == null) {\n  throw new Error(\n    'perf-deets currently only supports browser and web worker environments. ' +\n      'Other environments should alias the package to `perf-deets/noop`.'\n  );\n}\n\n// Add a listener to handle start/stop events\nglobalThis.addEventListener('message', e => {\n  switch (e.data.type) {\n    case '__perf-deets:start-profile':\n      start();\n      break;\n    case '__perf-deets:stop-profile':\n      stop();\n      break;\n    // In the case of nested workers, we want to propagate these\n    // events up to the main thread. Note that this assumes the perf\n    // library is loaded throughout the whole worker tree. If one of\n    // the child workers doesn't load, this listener won't run and\n    // data will be lost\n    case '__perf-deets:clear-perf':\n    case '__perf-deets:log-perf':\n      if (typeof window === 'undefined') {\n        self.postMessage(e.data);\n      }\n  }\n});\n\n\n//# sourceURL=webpack:///../../node_modules/perf-deets/index.js?");

/***/ }),

/***/ "../indexeddb/shared-channel.js":
/*!**************************************!*\
  !*** ../indexeddb/shared-channel.js ***!
  \**************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Reader\": () => (/* binding */ Reader),\n/* harmony export */   \"Writer\": () => (/* binding */ Writer)\n/* harmony export */ });\nlet FINALIZED = 0xdeadbeef;\n\nlet WRITEABLE = 0;\nlet READABLE = 1;\n\nclass Reader {\n  constructor(\n    buffer,\n    { initialOffset = 4, useAtomics = true, stream = true, debug, name } = {}\n  ) {\n    this.buffer = buffer;\n    this.atomicView = new Int32Array(buffer);\n    this.offset = initialOffset;\n    this.useAtomics = useAtomics;\n    this.stream = stream;\n    this.debug = debug;\n    this.name = name;\n  }\n\n  log(...args) {\n    if (this.debug) {\n      console.log(`[reader: ${this.name}]`, ...args);\n    }\n  }\n\n  waitWrite(name, timeout = null) {\n    if (this.useAtomics) {\n      this.log(`waiting for ${name}`);\n\n      while (Atomics.load(this.atomicView, 0) === WRITEABLE) {\n        if (timeout != null) {\n          if (\n            Atomics.wait(this.atomicView, 0, WRITEABLE, timeout) === 'timed-out'\n          ) {\n            throw new Error('timeout');\n          }\n        }\n\n        Atomics.wait(this.atomicView, 0, WRITEABLE, 500);\n      }\n\n      this.log(`resumed for ${name}`);\n    } else {\n      if (this.atomicView[0] !== READABLE) {\n        throw new Error('`waitWrite` expected array to be readable');\n      }\n    }\n  }\n\n  flip() {\n    this.log('flip');\n    if (this.useAtomics) {\n      let prev = Atomics.compareExchange(\n        this.atomicView,\n        0,\n        READABLE,\n        WRITEABLE\n      );\n\n      if (prev !== READABLE) {\n        throw new Error('Read data out of sync! This is disastrous');\n      }\n\n      Atomics.notify(this.atomicView, 0);\n    } else {\n      this.atomicView[0] = WRITEABLE;\n    }\n\n    this.offset = 4;\n  }\n\n  done() {\n    this.waitWrite('done');\n\n    let dataView = new DataView(this.buffer, this.offset);\n    let done = dataView.getUint32(0) === FINALIZED;\n\n    if (done) {\n      this.log('done');\n      this.flip();\n    }\n\n    return done;\n  }\n\n  peek(fn) {\n    this.peekOffset = this.offset;\n    let res = fn();\n    this.offset = this.peekOffset;\n    this.peekOffset = null;\n    return res;\n  }\n\n  string(timeout) {\n    this.waitWrite('string', timeout);\n\n    let byteLength = this._int32();\n    let length = byteLength / 2;\n\n    let dataView = new DataView(this.buffer, this.offset, byteLength);\n    let chars = [];\n    for (let i = 0; i < length; i++) {\n      chars.push(dataView.getUint16(i * 2));\n    }\n    let str = String.fromCharCode.apply(null, chars);\n    this.log('string', str);\n\n    this.offset += byteLength;\n\n    if (this.peekOffset == null) {\n      this.flip();\n    }\n    return str;\n  }\n\n  _int32() {\n    let byteLength = 4;\n\n    let dataView = new DataView(this.buffer, this.offset);\n    let num = dataView.getInt32();\n    this.log('_int32', num);\n\n    this.offset += byteLength;\n    return num;\n  }\n\n  int32() {\n    this.waitWrite('int32');\n    let num = this._int32();\n    this.log('int32', num);\n\n    if (this.peekOffset == null) {\n      this.flip();\n    }\n    return num;\n  }\n\n  bytes() {\n    this.waitWrite('bytes');\n\n    let byteLength = this._int32();\n\n    let bytes = new ArrayBuffer(byteLength);\n    new Uint8Array(bytes).set(\n      new Uint8Array(this.buffer, this.offset, byteLength)\n    );\n    this.log('bytes', bytes);\n\n    this.offset += byteLength;\n\n    if (this.peekOffset == null) {\n      this.flip();\n    }\n    return bytes;\n  }\n}\n\nclass Writer {\n  constructor(\n    buffer,\n    { initialOffset = 4, useAtomics = true, stream = true, debug, name } = {}\n  ) {\n    this.buffer = buffer;\n    this.atomicView = new Int32Array(buffer);\n    this.offset = initialOffset;\n    this.useAtomics = useAtomics;\n    this.stream = stream;\n\n    this.debug = debug;\n    this.name = name;\n\n    if (this.useAtomics) {\n      // The buffer starts out as writeable\n      Atomics.store(this.atomicView, 0, WRITEABLE);\n    } else {\n      this.atomicView[0] = WRITEABLE;\n    }\n  }\n\n  log(...args) {\n    if (this.debug) {\n      console.log(`[writer: ${this.name}]`, ...args);\n    }\n  }\n\n  waitRead(name) {\n    if (this.useAtomics) {\n      this.log(`waiting for ${name}`);\n      // Switch to writable\n      // Atomics.store(this.atomicView, 0, 1);\n\n      let prev = Atomics.compareExchange(\n        this.atomicView,\n        0,\n        WRITEABLE,\n        READABLE\n      );\n\n      if (prev !== WRITEABLE) {\n        throw new Error(\n          'Wrote something into unwritable buffer! This is disastrous'\n        );\n      }\n\n      Atomics.notify(this.atomicView, 0);\n\n      while (Atomics.load(this.atomicView, 0) === READABLE) {\n        // console.log('waiting to be read...');\n        Atomics.wait(this.atomicView, 0, READABLE, 500);\n      }\n\n      this.log(`resumed for ${name}`);\n    } else {\n      this.atomicView[0] = READABLE;\n    }\n\n    this.offset = 4;\n  }\n\n  finalize() {\n    this.log('finalizing');\n    let dataView = new DataView(this.buffer, this.offset);\n    dataView.setUint32(0, FINALIZED);\n    this.waitRead('finalize');\n  }\n\n  string(str) {\n    this.log('string', str);\n\n    let byteLength = str.length * 2;\n    this._int32(byteLength);\n\n    let dataView = new DataView(this.buffer, this.offset, byteLength);\n    for (let i = 0; i < str.length; i++) {\n      dataView.setUint16(i * 2, str.charCodeAt(i));\n    }\n\n    this.offset += byteLength;\n    this.waitRead('string');\n  }\n\n  _int32(num) {\n    let byteLength = 4;\n\n    let dataView = new DataView(this.buffer, this.offset);\n    dataView.setInt32(0, num);\n\n    this.offset += byteLength;\n  }\n\n  int32(num) {\n    this.log('int32', num);\n    this._int32(num);\n    this.waitRead('int32');\n  }\n\n  bytes(buffer) {\n    this.log('bytes', buffer);\n\n    let byteLength = buffer.byteLength;\n    this._int32(byteLength);\n    new Uint8Array(this.buffer, this.offset).set(new Uint8Array(buffer));\n\n    this.offset += byteLength;\n    this.waitRead('bytes');\n  }\n}\n\n\n//# sourceURL=webpack:///../indexeddb/shared-channel.js?");

/***/ }),

/***/ "../indexeddb/worker.js":
/*!******************************!*\
  !*** ../indexeddb/worker.js ***!
  \******************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _shared_channel__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./shared-channel */ \"../indexeddb/shared-channel.js\");\n/* harmony import */ var perf_deets__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! perf-deets */ \"../../node_modules/perf-deets/index.js\");\n/* harmony import */ var _sqlite_util__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../sqlite-util */ \"../sqlite-util.js\");\n\n\n\n\nlet isProbablySafari = /^((?!chrome|android).)*safari/i.test(\n  navigator.userAgent\n);\n\n// Don't need a map anymore, we use a worker per file\nlet openDbs = new Map();\nlet transactions = new Map();\n\nfunction assert(cond, msg) {\n  if (!cond) {\n    throw new Error(msg);\n  }\n}\n\n// We use long-lived transactions, and `Transaction` keeps the\n// transaction state. It implements an optimal way to perform\n// read/writes with knowledge of how sqlite asks for them, and also\n// implements a locking mechanism that maps to how sqlite locks work.\nclass Transaction {\n  constructor(db, initialMode = 'readonly') {\n    this.db = db;\n    perf_deets__WEBPACK_IMPORTED_MODULE_1__.count('transactions');\n    this.trans = this.db.transaction(['data'], initialMode);\n    this.store = this.trans.objectStore('data');\n    this.lockType =\n      initialMode === 'readonly' ? _sqlite_util__WEBPACK_IMPORTED_MODULE_2__.LOCK_TYPES.SHARED : _sqlite_util__WEBPACK_IMPORTED_MODULE_2__.LOCK_TYPES.EXCLUSIVE;\n\n    // There is no need for us to cache blocks. Use sqlite's\n    // `cache_size` for that and it will automatically do it. However,\n    // we do still keep a cache of the first block for the duration of\n    // this transaction because of how locking works; this avoids a\n    // few extra reads and allows us to detect changes during\n    // upgrading (see `upgradeExclusive`)\n    this.cachedFirstBlock = null;\n\n    this.cursor = null;\n    this.prevReads = null;\n  }\n\n  async prefetchFirstBlock(timeout) {\n    // TODO: implement timeout\n\n    // Get the first block and cache it\n    let block = await this.get(0);\n    this.cachedFirstBlock = block;\n    return block;\n  }\n\n  async waitComplete() {\n    return new Promise((resolve, reject) => {\n      // Eagerly commit it for better perf. Note that **this assumes\n      // the transaction is open** as `commit` will throw an error if\n      // it's already closed (which should never be the case for us)\n      this.commit();\n\n      if (this.lockType === _sqlite_util__WEBPACK_IMPORTED_MODULE_2__.LOCK_TYPES.EXCLUSIVE) {\n        // Wait until all writes are committed\n        this.trans.oncomplete = e => resolve();\n\n        // TODO: Is it OK to add this later, after an error might have\n        // happened? Will it hold the error and fire this when we\n        // attached it? We might want to eagerly create the promise\n        // when creating the transaction and return it here\n        this.trans.onerror = e => reject(e);\n      } else {\n        if (isProbablySafari) {\n          // Safari has a bug where sometimes the IDB gets blocked\n          // permanently if you refresh the page with an open\n          // transaction. You have to restart the browser to fix it.\n          // We wait for readonly transactions to finish too, but this\n          // is a perf hit\n          this.trans.oncomplete = e => resolve();\n        } else {\n          // No need to wait on anything in a read-only transaction.\n          // Note that errors during reads area always handled by the\n          // read request.\n          resolve();\n        }\n      }\n    });\n  }\n\n  commit() {\n    // Safari doesn't support this method yet (this is just an\n    // optimization)\n    if (this.trans.commit) {\n      this.trans.commit();\n    }\n  }\n\n  async upgradeExclusive() {\n    this.commit();\n\n    // console.log('updating transaction readwrite');\n    perf_deets__WEBPACK_IMPORTED_MODULE_1__.count('transactions');\n    this.trans = this.db.transaction(['data'], 'readwrite');\n    this.store = this.trans.objectStore('data');\n    this.lockType = _sqlite_util__WEBPACK_IMPORTED_MODULE_2__.LOCK_TYPES.EXCLUSIVE;\n\n    let cached0 = this.cachedFirstBlock;\n\n    // Do a read\n    let block = await this.prefetchFirstBlock(500);\n    // TODO: when timeouts are implemented, detect timeout and return BUSY\n\n    return (0,_sqlite_util__WEBPACK_IMPORTED_MODULE_2__.isSafeToWrite)(block, cached0);\n  }\n\n  downgradeShared() {\n    this.commit();\n\n    // console.log('downgrading transaction readonly');\n    perf_deets__WEBPACK_IMPORTED_MODULE_1__.count('transactions');\n    this.trans = this.db.transaction(['data'], 'readonly');\n    this.store = this.trans.objectStore('data');\n    this.lockType = _sqlite_util__WEBPACK_IMPORTED_MODULE_2__.LOCK_TYPES.SHARED;\n  }\n\n  async get(key) {\n    return new Promise((resolve, reject) => {\n      perf_deets__WEBPACK_IMPORTED_MODULE_1__.record('get');\n      let req = this.store.get(key);\n      req.onsuccess = e => {\n        perf_deets__WEBPACK_IMPORTED_MODULE_1__.endRecording('get');\n        resolve(req.result);\n      };\n      req.onerror = e => reject(e);\n    });\n  }\n\n  getReadDirection() {\n    // There are a two ways we can read data: a direct `get` request\n    // or opening a cursor and iterating through data. We don't know\n    // what future reads look like, so we don't know the best strategy\n    // to pick. Always choosing one strategy forgoes a lot of\n    // optimization, because iterating with a cursor is a lot faster\n    // than many `get` calls. On the other hand, opening a cursor is\n    // slow, and so is calling `advance` to move a cursor over a huge\n    // range (like moving it 1000 items later), so many `get` calls would\n    // be faster. In general:\n    //\n    // * Many `get` calls are faster when doing random accesses\n    // * Iterating with a cursor is faster if doing mostly sequential\n    //   accesses\n    //\n    // We implement a heuristic and keeps track of the last 3 reads\n    // and detects when they are mostly sequential. If they are, we\n    // open a cursor and start reading by iterating it. If not, we do\n    // direct `get` calls.\n    //\n    // On top of all of this, each browser has different perf\n    // characteristics. We will probably want to make these thresholds\n    // configurable so the user can change them per-browser if needed,\n    // as well as fine-tuning them for their usage of sqlite.\n\n    let prevReads = this.prevReads;\n    if (prevReads) {\n      // Has there been 3 forward sequential reads within 10 blocks?\n      if (\n        prevReads[0] < prevReads[1] &&\n        prevReads[1] < prevReads[2] &&\n        prevReads[2] - prevReads[0] < 10\n      ) {\n        return 'next';\n      }\n\n      // Has there been 3 backwards sequential reads within 10 blocks?\n      if (\n        prevReads[0] > prevReads[1] &&\n        prevReads[1] > prevReads[2] &&\n        prevReads[0] - prevReads[2] < 10\n      ) {\n        return 'prev';\n      }\n    }\n\n    return null;\n  }\n\n  read(position) {\n    let waitCursor = () => {\n      return new Promise((resolve, reject) => {\n        if (this.cursorPromise != null) {\n          throw new Error(\n            'waitCursor() called but something else is already waiting'\n          );\n        }\n        this.cursorPromise = { resolve, reject };\n      });\n    };\n\n    if (this.cursor) {\n      let cursor = this.cursor;\n\n      if (\n        cursor.direction === 'next' &&\n        position > cursor.key &&\n        position < cursor.key + 100\n      ) {\n        perf_deets__WEBPACK_IMPORTED_MODULE_1__.record('stream-next');\n\n        cursor.advance(position - cursor.key);\n        return waitCursor();\n      } else if (\n        cursor.direction === 'prev' &&\n        position < cursor.key &&\n        position > cursor.key - 100\n      ) {\n        perf_deets__WEBPACK_IMPORTED_MODULE_1__.record('stream-next');\n\n        cursor.advance(cursor.key - position);\n        return waitCursor();\n      } else {\n        // Ditch the cursor\n        this.cursor = null;\n        return this.read(position);\n      }\n    } else {\n      // We don't already have a cursor. We need to a fresh read;\n      // should we open a cursor or call `get`?\n\n      let dir = this.getReadDirection();\n      if (dir) {\n        // Open a cursor\n        this.prevReads = null;\n\n        let keyRange;\n        if (dir === 'prev') {\n          keyRange = IDBKeyRange.upperBound(position);\n        } else {\n          keyRange = IDBKeyRange.lowerBound(position);\n        }\n\n        let req = this.store.openCursor(keyRange, dir);\n        perf_deets__WEBPACK_IMPORTED_MODULE_1__.record('stream');\n\n        req.onsuccess = e => {\n          perf_deets__WEBPACK_IMPORTED_MODULE_1__.endRecording('stream');\n          perf_deets__WEBPACK_IMPORTED_MODULE_1__.endRecording('stream-next');\n\n          let cursor = e.target.result;\n          this.cursor = cursor;\n\n          if (this.cursorPromise == null) {\n            throw new Error('Got data from cursor but nothing is waiting it');\n          }\n          this.cursorPromise.resolve(cursor ? cursor.value : null);\n          this.cursorPromise = null;\n        };\n        req.onerror = e => {\n          console.log('Cursor failure:', e);\n\n          if (this.cursorPromise == null) {\n            throw new Error('Got data from cursor but nothing is waiting it');\n          }\n          this.cursorPromise.reject(e);\n          this.cursorPromise = null;\n        };\n\n        return waitCursor();\n      } else {\n        if (this.prevReads == null) {\n          this.prevReads = [0, 0, 0];\n        }\n        this.prevReads.push(position);\n        this.prevReads.shift();\n\n        return this.get(position);\n      }\n    }\n  }\n\n  async set(item) {\n    this.prevReads = null;\n\n    return new Promise((resolve, reject) => {\n      let req = this.store.put(item.value, item.key);\n      req.onsuccess = e => resolve(req.result);\n      req.onerror = e => reject(e);\n    });\n  }\n\n  async bulkSet(items) {\n    this.prevReads = null;\n\n    for (let item of items) {\n      this.store.put(item.value, item.key);\n    }\n  }\n}\n\nasync function loadDb(name) {\n  return new Promise((resolve, reject) => {\n    if (openDbs.get(name)) {\n      resolve(openDbs.get(name));\n      return;\n    }\n\n    let req = globalThis.indexedDB.open(name, 2);\n    req.onsuccess = event => {\n      let db = event.target.result;\n\n      db.onversionchange = () => {\n        // TODO: Notify the user somehow\n        console.log('closing because version changed');\n        db.close();\n        openDbs.delete(name);\n      };\n\n      db.onclose = () => {\n        openDbs.delete(name);\n      };\n\n      openDbs.set(name, db);\n      resolve(db);\n    };\n    req.onupgradeneeded = event => {\n      let db = event.target.result;\n      if (!db.objectStoreNames.contains('data')) {\n        db.createObjectStore('data');\n      }\n    };\n    req.onblocked = e => console.log('blocked', e);\n    req.onerror = req.onabort = e => reject(e.target.error);\n  });\n}\n\nfunction closeDb(name) {\n  let openDb = openDbs.get(name);\n  if (openDb) {\n    openDb.close();\n    openDbs.delete(name);\n  }\n}\n\nfunction getTransaction(name) {\n  return transactions.get(name);\n}\n\nasync function withTransaction(name, mode, func) {\n  let trans = transactions.get(name);\n  if (trans) {\n    // If a transaction already exists, that means the file has been\n    // locked. We don't fully support arbitrary nested transactions,\n    // as seen below (we won't upgrade a `readonly` to `readwrite`\n    // automatically) and this is mainly for the use case where sqlite\n    // locks the db and creates a transaction for the duraction of the\n    // lock. We don't actually write code in a way that assumes nested\n    // transactions, so just error here\n    if (mode === 'readwrite' && trans.lockType === _sqlite_util__WEBPACK_IMPORTED_MODULE_2__.LOCK_TYPES.SHARED) {\n      throw new Error('Attempted write but only has SHARED lock');\n    }\n    return func(trans);\n  }\n\n  // Outside the scope of a lock, create a temporary transaction\n  trans = new Transaction(await loadDb(name), mode);\n  await func(trans);\n  await trans.waitComplete();\n}\n\n// Locking strategy:\n//\n// * We map sqlite's locks onto IndexedDB's transaction semantics.\n//   Read transactions may execute in parallel. Read/write\n//   transactions are queued up and wait until all preceding\n//   read transactions finish executing. Read transactions started\n//   after a read/write transaction wait until it is finished.\n//\n// * IDB transactions will wait forever until they can execute (for\n//   example, they may be blocked on a read/write transaction). We\n//   don't want to allow sqlite transactions to wait forever, so\n//   we manually timeout if a transaction takes too long to\n//   start executing. This simulates the behavior of a sqlite\n//   bailing if it can't require a lock.\n//\n// * A SHARED lock wants to read from the db. We start a read\n//   transaction and read the first block, and if we read it within\n//   500ms we consider the lock successful. Otherwise the lock\n//   failed and we return SQLITE_BUSY. (There's no perf downside\n//   to reading the first block - it has to be read anyway to check\n//   bytes 24-39 for the change counter)\n//\n// * A RESERVED lock means the db wants to start writing (think of\n//   `BEGIN TRANSACTION`). Only one process can obtain a RESERVED\n//   lock at a time, but normally sqlite still leads new read locks\n//   happen. It isn't until an EXCLUSIVE lock is held that reads are\n//   blocked. However, since we need to guarantee only one RESERVED\n//   lock at once (otherwise data could change from another process\n//   within a transaction, causing faulty caches etc) the simplest\n//   thing to do is go ahead and grab a read/write transaction that\n//   represents the RESERVED lock. This will block all reads from\n//   happening, and is essentially the same as an EXCLUSIVE lock.\n//\n//     * The main problem here is we can't \"upgrade\" a `readonly`\n//       transaction to `readwrite`, but native sqlite can upgrade a\n//       lock from SHARED to RESERVED. We need to start a new\n//       transaction to do so, and because of that there might be\n//       other `readwrite` transactions that get run during the\n//       \"upgrade\" which invalidates the whole locking process and\n//       and corrupts data.\n//\n// * Ideally, we could tell sqlite to skip SHARED locks entirely. We\n//   don't need them since we can rely on IndexedDB's semantics.\n//   Then when it wants to start writing, we get a RESERVED lock\n//   without having to upgrade from SHARED. This would save us\n//   the cost of a `readonly` transaction when writing; right now\n//   it must open a `readonly` transaction and then immediately open\n//   a `readwrite` to upgrade it. I thought of deferring opening the\n//   `readonly` transaction until something is actually read, but\n//   unfortunately sqlite opens it, reads the first block, and then\n//   upgrades it. So there's no way around it. (We can't assume it's\n//   a `readwrite` transaction at that point since that would assume\n//   all SHARED locks are `readwrite`, removing the possibility of\n//   concurrent reads).\n//\n// * Upgrading to an EXCLUSIVE lock is a noop, since we treat RESERVED\n//   locks as EXCLUSIVE.\nasync function handleLock(writer, name, lockType) {\n  // console.log('locking', name, lockType, performance.now());\n\n  let trans = transactions.get(name);\n  if (trans) {\n    if (lockType > trans.lockType) {\n      // Upgrade SHARED to EXCLUSIVE\n      assert(\n        trans.lockType === _sqlite_util__WEBPACK_IMPORTED_MODULE_2__.LOCK_TYPES.SHARED,\n        `Uprading lock type from ${trans.lockType} is invalid`\n      );\n      assert(\n        lockType === _sqlite_util__WEBPACK_IMPORTED_MODULE_2__.LOCK_TYPES.RESERVED || lockType === _sqlite_util__WEBPACK_IMPORTED_MODULE_2__.LOCK_TYPES.EXCLUSIVE,\n        `Upgrading lock type to ${lockType} is invalid`\n      );\n\n      let success = await trans.upgradeExclusive();\n      writer.int32(success ? 0 : -1);\n      writer.finalize();\n    } else {\n      // If not upgrading and we already have a lock, make sure this\n      // isn't a downgrade\n      assert(\n        trans.lockType === lockType,\n        `Downgrading lock to ${lockType} is invalid`\n      );\n\n      writer.int32(0);\n      writer.finalize();\n    }\n  } else {\n    assert(\n      lockType === _sqlite_util__WEBPACK_IMPORTED_MODULE_2__.LOCK_TYPES.SHARED,\n      `New locks must start as SHARED instead of ${lockType}`\n    );\n\n    let trans = new Transaction(await loadDb(name));\n    if ((await trans.prefetchFirstBlock(500)) == null) {\n      // BUSY\n    }\n\n    transactions.set(name, trans);\n\n    writer.int32(0);\n    writer.finalize();\n  }\n}\n\nasync function handleUnlock(writer, name, lockType) {\n  let trans = getTransaction(name);\n\n  if (lockType === _sqlite_util__WEBPACK_IMPORTED_MODULE_2__.LOCK_TYPES.SHARED) {\n    if (trans == null) {\n      throw new Error('Unlock error (SHARED): no transaction running');\n    }\n\n    if (trans.lockType === _sqlite_util__WEBPACK_IMPORTED_MODULE_2__.LOCK_TYPES.EXCLUSIVE) {\n      trans.downgradeShared();\n    }\n  } else if (lockType === _sqlite_util__WEBPACK_IMPORTED_MODULE_2__.LOCK_TYPES.NONE) {\n    // I thought we could assume a lock is always open when `unlock`\n    // is called, but it also calls `unlock` when closing the file no\n    // matter what. Do nothing if there's no lock currently\n    if (trans) {\n      // TODO: this is where an error could bubble up. Handle it\n      await trans.waitComplete();\n      transactions.delete(name);\n    }\n  }\n\n  writer.int32(0);\n  writer.finalize();\n}\n\nasync function handleRead(writer, name, position) {\n  return withTransaction(name, 'readonly', async trans => {\n    let data = await trans.read(position);\n\n    if (data == null) {\n      writer.bytes(new ArrayBuffer(0));\n    } else {\n      writer.bytes(data);\n    }\n    writer.finalize();\n  });\n}\n\nasync function handleWrites(writer, name, writes) {\n  return withTransaction(name, 'readwrite', async trans => {\n    await trans.bulkSet(writes.map(w => ({ key: w.pos, value: w.data })));\n\n    writer.int32(0);\n    writer.finalize();\n  });\n}\n\nasync function handleReadMeta(writer, name) {\n  return withTransaction(name, 'readonly', async trans => {\n    try {\n      console.log('Reading meta...');\n      let res = await trans.get(-1);\n      console.log(`Got meta for ${name}:`, res);\n\n      if (res == null) {\n        // No data yet\n        writer.int32(-1);\n        writer.int32(4096);\n        writer.finalize();\n      } else {\n        // let meta = res;\n\n        // Also read the first block to get the page size\n        let block = await trans.get(0);\n\n        // There should always be a first block if we have meta, but\n        // in case of a corrupted db, default to this size\n        let blockSize = 4096;\n        if (block) {\n          let arr = new Uint16Array(block);\n          blockSize = arr[8] * 256;\n        }\n\n        writer.int32(res.size);\n        writer.int32(blockSize);\n        writer.finalize();\n      }\n    } catch (err) {\n      console.log(err);\n      writer.int32(-1);\n      writer.int32(-1);\n      writer.finalize();\n    }\n  });\n}\n\nasync function handleWriteMeta(writer, name, meta) {\n  return withTransaction(name, 'readwrite', async trans => {\n    try {\n      await trans.set({ key: -1, value: meta });\n\n      writer.int32(0);\n      writer.finalize();\n    } catch (err) {\n      console.log(err);\n      writer.int32(-1);\n      writer.finalize();\n    }\n  });\n}\n\n// `listen` continually listens for requests via the shared buffer.\n// Right now it's implemented in a tail-call style (`listen` is\n// recursively called) because I thought that was necessary for\n// various reasons. We can convert this to a `while(1)` loop with\n// and use `await` though\nasync function listen(reader, writer) {\n  let method = reader.string();\n\n  switch (method) {\n    case 'profile-start': {\n      reader.done();\n\n      perf_deets__WEBPACK_IMPORTED_MODULE_1__.start();\n\n      writer.int32(0);\n      writer.finalize();\n      listen(reader, writer);\n      break;\n    }\n\n    case 'profile-stop': {\n      reader.done();\n\n      perf_deets__WEBPACK_IMPORTED_MODULE_1__.stop();\n      // The perf library posts a message; make sure it has time to\n      // actually post it before blocking the thread again\n      await new Promise(resolve => setTimeout(resolve, 1000));\n\n      writer.int32(0);\n      writer.finalize();\n      listen(reader, writer);\n      break;\n    }\n\n    case 'writeBlocks': {\n      let name = reader.string();\n      let writes = [];\n      while (!reader.done()) {\n        let pos = reader.int32();\n        let data = reader.bytes();\n        writes.push({ pos, data });\n      }\n\n      await handleWrites(writer, name, writes);\n      listen(reader, writer);\n      break;\n    }\n\n    case 'readBlock': {\n      let name = reader.string();\n      let pos = reader.int32();\n      reader.done();\n\n      await handleRead(writer, name, pos);\n      listen(reader, writer);\n      break;\n    }\n\n    case 'readMeta': {\n      let name = reader.string();\n      reader.done();\n      await handleReadMeta(writer, name);\n      listen(reader, writer);\n      break;\n    }\n\n    case 'writeMeta': {\n      let name = reader.string();\n      let size = reader.int32();\n      // let blockSize = reader.int32();\n      reader.done();\n      await handleWriteMeta(writer, name, { size });\n      listen(reader, writer);\n      break;\n    }\n\n    case 'closeFile': {\n      let name = reader.string();\n      reader.done();\n\n      // This worker is done, shut down\n      writer.int32(0);\n      writer.finalize();\n      closeDb(name);\n      self.close();\n      break;\n    }\n\n    case 'lockFile': {\n      let name = reader.string();\n      let lockType = reader.int32();\n      reader.done();\n\n      await handleLock(writer, name, lockType);\n      listen(reader, writer);\n      break;\n    }\n\n    case 'unlockFile': {\n      let name = reader.string();\n      let lockType = reader.int32();\n      reader.done();\n\n      await handleUnlock(writer, name, lockType);\n      listen(reader, writer);\n      break;\n    }\n\n    default:\n      throw new Error('Unknown method: ' + method);\n  }\n}\n\nself.onmessage = msg => {\n  switch (msg.data.type) {\n    case 'init': {\n      // postMessage({ type: '__absurd:worker-ready' });\n      let [argBuffer, resultBuffer] = msg.data.buffers;\n      let reader = new _shared_channel__WEBPACK_IMPORTED_MODULE_0__.Reader(argBuffer, { name: 'args', debug: false });\n      let writer = new _shared_channel__WEBPACK_IMPORTED_MODULE_0__.Writer(resultBuffer, { name: 'results', debug: false });\n      listen(reader, writer);\n      break;\n    }\n  }\n};\n\n\n//# sourceURL=webpack:///../indexeddb/worker.js?");

/***/ }),

/***/ "../sqlite-util.js":
/*!*************************!*\
  !*** ../sqlite-util.js ***!
  \*************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"LOCK_TYPES\": () => (/* binding */ LOCK_TYPES),\n/* harmony export */   \"getPageSize\": () => (/* binding */ getPageSize),\n/* harmony export */   \"isSafeToWrite\": () => (/* binding */ isSafeToWrite)\n/* harmony export */ });\nlet LOCK_TYPES = {\n  NONE: 0,\n  SHARED: 1,\n  RESERVED: 2,\n  PENDING: 3,\n  EXCLUSIVE: 4\n};\n\nfunction getPageSize(bufferView) {\n  // See 1.3.2 on https://www.sqlite.org/fileformat.html The page size\n  // is stored as a 2 byte integer at the 16th byte. It's stored as\n  // big-endian so the first byte is the larger one. Combine it into a\n  // single integer.\n  let int1 = bufferView[16];\n  let int2 = bufferView[17];\n  return (int1 << 8) + int2;\n}\n\nfunction isSafeToWrite(localData, diskData) {\n  if (localData != null && diskData != null) {\n    let localView = new Uint8Array(localData);\n    let diskView = new Uint8Array(diskData);\n\n    // See\n    // https://github.com/sqlite/sqlite/blob/master/src/pager.c#L93-L96\n    // (might be documented somewhere? I didn't see it this clearly in\n    // the docs). At least one of these bytes change when sqlite3 writes\n    // data. We can check this against our in-memory data to see if it's\n    // safe to write (if something changes underneath us, it's not)\n    for (let i = 24; i < 40; i++) {\n      if (localView[i] !== diskView[i]) {\n        return false;\n      }\n    }\n    return true;\n  }\n\n  // One of them is null, so it's only safe if to write if both are\n  // null, otherwise they are different\n  return localData == null && diskData == null;\n}\n\n\n//# sourceURL=webpack:///../sqlite-util.js?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId](module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module can't be inlined because the eval devtool is used.
/******/ 	var __webpack_exports__ = __webpack_require__("../indexeddb/worker.js");
/******/ 	
/******/ })()
;